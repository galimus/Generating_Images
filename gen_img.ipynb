{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import cv2\n"
      ],
      "metadata": {
        "id": "x_qlNBxRFVTa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_directory = \"/content/images\""
      ],
      "metadata": {
        "id": "yEDo8jKMFggo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_paths = glob.glob(image_directory + \"/*.png\")\n",
        "images = []\n",
        "for path in image_paths:\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (28, 28))\n",
        "    img = img.astype(\"float32\") / 255.0\n",
        "    img = (img - 0.5) / 0.5  # Normalize to the range of -1 to 1\n",
        "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "    images.append(img)"
      ],
      "metadata": {
        "id": "SbeRxlSfFkB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "image_paths = glob.glob(image_directory + \"/*.png\")\n",
        "images = []\n",
        "\n",
        "for path in image_paths:\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, (28, 28))\n",
        "\n",
        "    img_bgr = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    img_rgb = img_rgb.astype(\"float32\") / 127.5 - 1.0\n",
        "\n",
        "    images.append(img_rgb)\n",
        "\n",
        "\n",
        "x_train = np.array(images)\n",
        "\n",
        "\n",
        "print(\"Image shape:\", x_train.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYmfWxBrVh52",
        "outputId": "27ab254a-1507-4008-a8df-933fcd4c3207"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image shape: (5, 28, 28, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "i2yzqBLVDHfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "id": "STa08IXQV2AZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator model\n",
        "def build_generator(latent_dim):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Dense(7 * 7 * 256, input_dim=latent_dim))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    model.add(layers.Conv2DTranspose(128, kernel_size=5, strides=1, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2DTranspose(64, kernel_size=5, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2DTranspose(3, kernel_size=5, strides=2, padding=\"same\", activation=\"tanh\"))  # Update output channels to 3\n",
        "    return model\n",
        "\n",
        "# Discriminator model\n",
        "def build_discriminator():\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Conv2D(64, kernel_size=5, strides=2, padding=\"same\", input_shape=(28, 28, 3)))  # Update input channels to 3\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Conv2D(128, kernel_size=5, strides=2, padding=\"same\"))\n",
        "    model.add(layers.LeakyReLU(alpha=0.2))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "O7BtrtiEDLON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VECK_jSKDPJ_",
        "outputId": "c66375a8-a145-4f2a-c002-0cf089293b41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8ikef2vBx-m"
      },
      "outputs": [],
      "source": [
        "\n",
        "latent_dim = 100\n",
        "\n",
        "\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(), metrics=[\"accuracy\"])\n",
        "\n",
        "\n",
        "generator = build_generator(latent_dim)\n",
        "\n",
        "gan = keras.Sequential([generator, discriminator])\n",
        "gan.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam())\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(-1, 28, 28, 3)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_train = (x_train - 127.5) / 127.5\n",
        "\n",
        "# Training loop\n",
        "batch_size = 128\n",
        "epochs = 10000\n",
        "sample_interval = 100\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(epochs):\n",
        "\n",
        "    idx = np.random.randint(0, x_train.shape[0], batch_size)\n",
        "    real_images = x_train[idx]\n",
        "\n",
        "\n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    fake_images = generator.predict(noise)\n",
        "\n",
        "    \n",
        "    discriminator_loss_real = discriminator.train_on_batch(real_images, np.ones((batch_size, 1)))\n",
        "    discriminator_loss_fake = discriminator.train_on_batch(fake_images, np.zeros((batch_size, 1)))\n",
        "    discriminator_loss = 0.5 * np.add(discriminator_loss_real, discriminator_loss_fake)\n",
        "\n",
        "  \n",
        "    noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "    generator_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "    # Print the progress\n",
        "    if epoch % sample_interval == 0:\n",
        "        print(f\"Epoch {epoch}/{epochs} | Discriminator Loss: {discriminator_loss[0]} | Discriminator Accuracy: {100 * discriminator_loss[1]}%\")\n",
        "        print(f\"Generator Loss: {generator_loss}\")\n",
        "\n",
        "        # Generate and save a sample of generated images\n",
        "        if epoch % sample_interval == 0:\n",
        "            # Generate images from random noise\n",
        "            noise = np.random.normal(0, 1, (16, latent_dim))\n",
        "            generated_images = generator.predict(noise)\n",
        "\n",
        "            # Rescale images to 0-1 range\n",
        "            generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "            # Save the generated images\n",
        "            for i in range(generated_images.shape[0]):\n",
        "                img = generated_images[i]\n",
        "                img = np.clip(img * 255, 0, 255).astype('uint8')\n",
        "                img = Image.fromarray(img, 'RGB')\n",
        "                img.save(f\"/content/gen4/{epoch}_{i}.png\")\n"
      ],
      "metadata": {
        "id": "cX_pKQV1TK3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/gen2.zip /content/gen2\n"
      ],
      "metadata": {
        "id": "Gw3eRJsUGxSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a6uHnjTlKF05"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}